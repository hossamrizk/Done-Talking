# ğŸ¤ Done-Talking

> â€œToo much talk? Iâ€™ll handle it.â€

**Done-Talking** is a local-first, privacy-friendly pipeline that takes long, messy audioâ€”whether from uploaded files or video linksâ€”and delivers clean, human-readable summaries and key insights.

---

## ğŸ§  What It Does

- Accepts a **video URL** or **uploaded audio**.
- If video: downloads and extracts audio.
- Performs **speaker diarization** with `pyannote.audio` to separate voices.
- Transcribes using **OpenAI Whisper** (locally).
- Summarizes the transcript + extracts key points using **Ollama local models**.
- All processing runs **locally**, except for the summary model hosted on **Colab GPU**.
- Outputs a concise **.txt file** with the final summary.

---

## ğŸš€ Features

- âœ… Video URL input (e.g., YouTube)
- âœ… Local audio file support (`.mp3`, `.wav`, etc.)
- âœ… Multi-speaker diarization via `pyannote.audio`
- âœ… Whisper-based transcription
- âœ… Summarization using Ollama-hosted LLMs (e.g., Mistral, LLaMA 3)
- âœ… Key points extraction
- âœ… Offline-first, with remote LLM support via Colab
- âœ… Final output saved as `.txt`

---

## ğŸ”— API Endpoints

The project includes three REST API endpoints:

| Endpoint          | Method | Description |
|-------------------|--------|-------------|
| `/`               | GET    | Returns basic app info |
| `/download_audio` | POST   | Accepts a JSON body: `{ "video_url": "<url>" }` and downloads + processes audio |
| `/upload_audio`   | POST   | Accepts a `multipart/form-data` audio file upload (from userâ€™s PC) |

---

## ğŸ”§ Tech Stack

| Component           | Tool                     |
|--------------------|--------------------------|
| Audio/Video Handling | `moviepy`, `ffmpeg`     |
| Diarization         | `pyannote.audio`         |
| Transcription       | `whisper`                |
| Summarization       | `ollama` (hosted on Colab) |
| API Server          | `Flask`                  |
| File I/O            | `os`, `tempfile`, `shutil`, `pathlib` |

---

## ğŸ“ Folder Structure

```bash
done-talking/
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ assets/
â”‚   â”‚   â”œâ”€â”€ generated_reports/
â”‚   â”‚   â”œâ”€â”€ downloaded_audios/
â”‚   â”‚   â””â”€â”€ uploaded_audios/
â”‚   â”‚
â”‚   â”œâ”€â”€ helpers/
â”‚   â”‚   â””â”€â”€ file_helpers.py
â”‚   â”‚
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ ollama_model.py
â”‚   â”‚
â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â””â”€â”€ api_routes.py
â”‚   â”‚
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ download_video.py
â”‚   â”‚   â”œâ”€â”€ diarize.py
â”‚   â”‚   â”œâ”€â”€ transcribe.py
â”‚   â”‚   â””â”€â”€ summarize.py
â”‚   â”‚
â”‚   â”œâ”€â”€ .env
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ main.py
â”‚
â”œâ”€â”€ LICENSE
â”œâ”€â”€ README.md
â””â”€â”€ colab_server.ipynb
```

## ğŸ§ª How to Run

1. Clone the repo

```bash
git clone https://github.com/your-username/done-talking.git
cd done-talking
```

1. Install dependencies:

```bash
pip install -r requirements.txt
```

1. Run

```bash
uvicorn main:app --port 8000 --host 0.0.0.0
```

## ğŸ’¡ Example Use Cases

Meeting summarizer

Podcast note-taker

Lecture distiller

Multi-speaker content analyzer

## ğŸ“œ License

This project is licensed under the MIT License. See the `LICENSE` file for details.
